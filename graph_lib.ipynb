{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9REjiR7FxLky"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1648711983009,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "9uKD3smEvSec"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1648711983011,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "SRn5zviK9mab",
    "outputId": "0e97d487-6b1e-4634-ae2c-a353ac1e4440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5031,
     "status": "ok",
     "timestamp": 1648711988032,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "F8Gbla5EAnuT",
    "outputId": "62ae1b95-2a71-46eb-f610-9874754e00b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graph_nets in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: dm-sonnet in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: tensorflow_probability in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (0.1.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (2.6.3)\n",
      "Requirement already satisfied: future in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.22.2)\n",
      "Requirement already satisfied: six in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (57.4.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.0.0)\n",
      "Requirement already satisfied: tabulate>=0.7.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-sonnet) (0.8.9)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-sonnet) (1.13.3)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (0.5.3)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (2.0.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install graph_nets  dm-sonnet tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1648711988033,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "dmcb7EBvvoyF"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB and 'drive' not in os.listdir(\"/content\"):\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648711988034,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "kSW2Lvxg86fC"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    os.chdir('/content/drive/MyDrive/bakalarka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5044,
     "status": "ok",
     "timestamp": 1648711993068,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "VciOHpBLwvLT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from graph_nets import utils_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from EncodeProcessDecodeBasic import EncodeProcessDecode\n",
    "from EncodeProcessDecodeNorm import EncodeProcessDecode as EncodeProcessDecodeNorm\n",
    "from EncodeProcessDecodeAddNorm import EncodeProcessDecode as EncodeProcessDecodeAddNorm\n",
    "from EncodeProcessDecodeNoLib import EncodeProcessDecode as EncodeProcessDecodeNoLib\n",
    "from EncodeProcessDecodeMultinet import EncodeProcessDecode as EncodeProcessDecodeMultinet\n",
    "from EncodeProcessDecodeNamedMultinet import EncodeProcessDecode as EncodeProcessDecodeNamedMultinet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "mod = \"named-full\"\n",
    "models = {\"basic\": {\"model\": EncodeProcessDecode,\n",
    "                    \"args\": {\"steps\": 15,\n",
    "                             \"learn_features\": 2,\n",
    "                             \"node_net_sizes\": [128] * 2 + [2],\n",
    "                             \"edge_net_sizes\": [128] * 2 + [4]},\n",
    "                    \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                    size=2, batch=1)]},\n",
    "          \"small_test\": {\"model\": EncodeProcessDecode,\n",
    "                         \"args\": {\"steps\": 5,\n",
    "                                  \"learn_features\": 2,\n",
    "                                  \"node_net_sizes\": [8] * 2 + [2],\n",
    "                                  \"edge_net_sizes\": [8] * 2 + [4]},\n",
    "                         \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                         size=2, batch=1)]},\n",
    "          \"full\": {\"model\": EncodeProcessDecodeNorm,\n",
    "                   \"args\": {\"steps\": 15,\n",
    "                            \"learn_features\": 2,\n",
    "                            \"n_layers\": 2,\n",
    "                            \"lat_size\": 128,\n",
    "                            \"edge_feat_cnt\": 3,\n",
    "                            \"node_feat_cnt\": 5},\n",
    "                   \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                   size=2, batch=1)]},\n",
    "          \"no-norm\": {\"model\": EncodeProcessDecodeNorm,\n",
    "                      \"args\": {\"steps\": 15,\n",
    "                               \"learn_features\": 2,\n",
    "                               \"n_layers\": 2,\n",
    "                               \"lat_size\": 128,\n",
    "                               \"edge_feat_cnt\": 3,\n",
    "                               \"node_feat_cnt\": 5,\n",
    "                               \"la_norm\": False},\n",
    "                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                      size=2, batch=1)]},\n",
    "          \"add\": {\"model\": EncodeProcessDecodeAddNorm,\n",
    "                  \"args\": {\"steps\": 15,\n",
    "                           \"learn_features\": 2,\n",
    "                           \"n_layers\": 2,\n",
    "                           \"lat_size\": 128,\n",
    "                           \"edge_feat_cnt\": 3,\n",
    "                           \"node_feat_cnt\": 5},\n",
    "                  \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                  size=2, batch=1)]},\n",
    "          \"no-lib\": {\"model\": EncodeProcessDecodeNoLib,\n",
    "                     \"args\": {\"steps\": 15,\n",
    "                              \"learn_features\": 2,\n",
    "                              \"n_layers\": 2,\n",
    "                              \"lat_size\": 128,\n",
    "                              \"edge_feat_cnt\": 3,\n",
    "                              \"node_feat_cnt\": 5},\n",
    "                     \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                     size=2, batch=1)]},\n",
    "          \"multinet\": {\"model\": EncodeProcessDecodeMultinet,\n",
    "                       \"args\": {\"steps\": 15,\n",
    "                                \"learn_features\": 2,\n",
    "                                \"n_layers\": 2,\n",
    "                                \"lat_size\": 128,\n",
    "                                \"edge_feat_cnt\": 3,\n",
    "                                \"node_feat_cnt\": 5},\n",
    "                       \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                       size=2, batch=2)]},\n",
    "          \"named\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                    \"args\": {\"steps\": 15,\n",
    "                             \"learn_features\": 2,\n",
    "                             \"n_layers\": 2,\n",
    "                             \"lat_size\": 128,\n",
    "                             \"edge_feat_cnt\": 3,\n",
    "                             \"node_feat_cnt\": 5},\n",
    "                    \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                    size=2, batch=2)]},\n",
    "          \"named18\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                      \"args\": {\"steps\": 18,\n",
    "                               \"learn_features\": 2,\n",
    "                               \"n_layers\": 2,\n",
    "                               \"lat_size\": 128,\n",
    "                               \"edge_feat_cnt\": 3,\n",
    "                               \"node_feat_cnt\": 5},\n",
    "                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                      size=2, batch=2)]},\n",
    "          \"named12\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                      \"args\": {\"steps\": 12,\n",
    "                               \"learn_features\": 2,\n",
    "                               \"n_layers\": 2,\n",
    "                               \"lat_size\": 128,\n",
    "                               \"edge_feat_cnt\": 3,\n",
    "                               \"node_feat_cnt\": 5},\n",
    "                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                      size=2, batch=2)]},\n",
    "          \"named-full\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                         \"args\": {\"steps\": 15,\n",
    "                                  \"learn_features\": 4,\n",
    "                                  \"n_layers\": 2,\n",
    "                                  \"lat_size\": 128,\n",
    "                                  \"edge_feat_cnt\": 3,\n",
    "                                  \"node_feat_cnt\": 7},\n",
    "                         \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                         size=2, batch=2),\n",
    "                                    dict(noise=0.02, gamma=1.0, field='pressure', history=False,\n",
    "                                         size=1, batch=2),\n",
    "                                    dict(noise=0.02, gamma=1.0, field='density', history=False,\n",
    "                                         size=1, batch=2)]}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1648711993070,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "FaXyDwZGx59F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = models[mod][\"params\"]\n",
    "targets = tuple([x[\"field\"] for x in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1648711993071,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "_na6wHrgyG8F"
   },
   "outputs": [],
   "source": [
    "from common import NodeType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVLsMSLjxSQz"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1648711993071,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "FYCTQTvKxrOv"
   },
   "outputs": [],
   "source": [
    "data_path = 'data/airfoil'\n",
    "data_train = 'small' if IN_COLAB else 'train'\n",
    "data_valid = 'small' if IN_COLAB else 'valid'\n",
    "data_test = 'small' if IN_COLAB else 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from dataset import load_dataset, split_dataset, prepare, add_noises, add_targets, add_batch, triangles_to_edges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(data_path, data_train)\n",
    "ds = add_targets(ds, targets, add_history=params[0]['history'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ds = split_dataset(ds)\n",
    "for param in params:\n",
    "    ds = add_noises(ds, noise_field=param['field'],\n",
    "                    noise_scale=param['noise'],\n",
    "                    noise_gamma=param['gamma'])\n",
    "ds = prepare(ds, 100 if IN_COLAB else 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "ds = add_batch(ds, params[0]['batch'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare for learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "itr = iter(ds)\n",
    "d = itr.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "NodeTypeCnt = tf.unique(tf.reshape(d['node_type'], d['node_type'].shape[:1])).y.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def toGraphsTuple(d, targets=('velocity',)):\n",
    "    send, recive = triangles_to_edges(d['cells'])\n",
    "    rel_pos = (tf.gather(d['mesh_pos'], send) - tf.gather(d['mesh_pos'], recive))\n",
    "    nodes_unique = tf.unique_with_counts(tf.reshape(d[\"node_type\"], [-1]))\n",
    "    one_hot = tf.one_hot(nodes_unique.idx, NodeTypeCnt, dtype=tf.float32)\n",
    "    dd = {\n",
    "        \"nodes\": tf.concat([*[d[x] for x in targets], one_hot], 1),\n",
    "        # on change update loss function ^\n",
    "        \"senders\": send,\n",
    "        \"receivers\": recive,\n",
    "        \"edges\": tf.concat([\n",
    "            rel_pos,\n",
    "            tf.norm(rel_pos, axis=-1, keepdims=True)], 1)\n",
    "    }\n",
    "    return utils_tf.data_dicts_to_graphs_tuple([dd])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dd = toGraphsTuple(d, targets)\n",
    "LINEAR_FEATURES = dd.nodes.shape[1] - NodeTypeCnt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "GraphsTuple(nodes=<tf.Tensor: shape=(10466, 5), dtype=float32, numpy=\narray([[131.9859  ,  20.154928,   1.      ,   0.      ,   0.      ],\n       [151.5147  ,  21.275198,   1.      ,   0.      ,   0.      ],\n       [162.18492 ,  23.188953,   1.      ,   0.      ,   0.      ],\n       ...,\n       [ 87.38186 , -25.509438,   0.      ,   0.      ,   1.      ],\n       [ 87.445595, -25.126059,   0.      ,   0.      ,   1.      ],\n       [ 87.46395 , -25.380064,   0.      ,   0.      ,   1.      ]],\n      dtype=float32)>, edges=<tf.Tensor: shape=(61796, 3), dtype=float32, numpy=\narray([[ 0.00579996, -0.01206488,  0.01338659],\n       [-0.00720367, -0.01440071,  0.01610196],\n       [-0.00630522,  0.0145334 ,  0.0158422 ],\n       ...,\n       [ 0.30951977,  1.4802246 ,  1.5122392 ],\n       [ 1.0828505 ,  1.8325498 ,  2.1285684 ],\n       [-0.43042946,  1.2830333 ,  1.3533084 ]], dtype=float32)>, receivers=<tf.Tensor: shape=(61796,), dtype=int32, numpy=array([   69,    55,   159, ..., 10294, 10339, 10342])>, senders=<tf.Tensor: shape=(61796,), dtype=int32, numpy=array([  417,   302,   405, ..., 10262, 10330, 10308])>, globals=None, n_node=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([10466])>, n_edge=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([61796])>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "aa = itr.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model and loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from AdamModLr import Adam\n",
    "\n",
    "lr = 1e-4\n",
    "# opt = snt.optimizers.Adam(lr)\n",
    "opt = Adam(lr)\n",
    "steps = 15\n",
    "#model = EncodeProcessDecode(steps, LINEAR_FEATURES, [128] * 2, [128] * 2 + [4])\n",
    "md = models[mod]\n",
    "model = md[\"model\"](**md[\"args\"])\n",
    "initial_learning_rate = lr\n",
    "decay_rate = 0.1\n",
    "decay_steps = 5e6\n",
    "learning_increase = 1e-6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def decayed_learning_rate(step):\n",
    "    return initial_learning_rate * decay_rate ** (step / decay_steps) + learning_increase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def update_step(data, targets=('velocity')):\n",
    "    print(\"Tracing!\")\n",
    "    grp = toGraphsTuple(data, targets)\n",
    "    with tf.GradientTape() as tape:\n",
    "        los = model.loss(grp, data)  #change to loss\n",
    "\n",
    "    gradients = tape.gradient(los, model.trainable_variables)\n",
    "\n",
    "    opt.apply(gradients, model.trainable_variables)\n",
    "    return los"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(20932, 2), dtype=float32, numpy=\narray([[139.44173 ,  17.464241],\n       [146.86493 ,  20.99404 ],\n       [152.6463  ,  21.979895],\n       ...,\n       [202.40822 ,  53.653122],\n       [202.47234 ,  53.66796 ],\n       [202.45268 ,  53.643192]], dtype=float32)>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([x['velocity'] for x in [aa, aa]], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "Tracing!\n"
     ]
    }
   ],
   "source": [
    "update_step(aa, targets);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss(grp, data):\n",
    "    return model.loss(grp, data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    logdir = 'logs/tst/'\n",
    "    writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "    # Bracket the function call with\n",
    "    # tf.summary.trace_on() and tf.summary.trace_export().\n",
    "    tf.summary.trace_on(graph=True, profiler=True)\n",
    "    # Call only one tf.function when tracing.\n",
    "    z = loss(dd, d)\n",
    "    with writer.as_default():\n",
    "        tf.summary.trace_export(\n",
    "            name=\"my_func_trace\",\n",
    "            step=0,\n",
    "            profiler_outdir=logdir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading models/namednet/named-197\n"
     ]
    }
   ],
   "source": [
    "chck_root = \"models/namednet/\"\n",
    "chck_name = mod\n",
    "\n",
    "chck = tf.train.Checkpoint(module=model)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(chck_root)\n",
    "if latest is not None:\n",
    "    print(\"loading\", latest)\n",
    "    chck.restore(latest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "if latest is None and not isinstance(model, EncodeProcessDecode):\n",
    "    print(\"Acumulating\")\n",
    "    for i in range(1000):\n",
    "        data = itr.next()\n",
    "        grp = toGraphsTuple(data, targets)\n",
    "        model.loss(grp, data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "i 7880000 mse: 0.10028864\n"
     ]
    }
   ],
   "source": [
    "colab_train = False\n",
    "start = 0\n",
    "sm_print = 500\n",
    "save_itr = 40000\n",
    "if not IN_COLAB or colab_train:\n",
    "    if latest is not None:\n",
    "        start = int(re.findall('\\d+$', latest)[0]) * save_itr\n",
    "    t = time.time()\n",
    "    print(\"training\")\n",
    "    sys.stdout.flush()\n",
    "    for i in range(start, int(1e7) + 1):\n",
    "        a = itr.next()\n",
    "        m = update_step(a, targets)\n",
    "        if i % sm_print == 0:\n",
    "            opt.learning_rate.assign(decayed_learning_rate(i))\n",
    "            print(\"i\", i, \"mse:\", m.numpy())\n",
    "            if i and i % save_itr == 0:\n",
    "                sys.stdout.flush()\n",
    "                chck.save(chck_root + chck_name)\n",
    "    print(time.time() - t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2140,
     "status": "ok",
     "timestamp": 1648712096478,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "F4Xnsg7MpzaY",
    "outputId": "4bc507ed-b22e-4d57-9096-b1e0f3c2dcea"
   },
   "outputs": [],
   "source": [
    "chck_root = \"models/namednet/\"\n",
    "chck_name = mod\n",
    "\n",
    "chck = tf.train.Checkpoint(module=model)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(chck_root)\n",
    "if latest is not None:\n",
    "    print(\"loading\", latest)\n",
    "    chck.restore(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1648712096481,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "JgZu39MbJi_z"
   },
   "outputs": [],
   "source": [
    "if latest is None and not isinstance(model, EncodeProcessDecode):\n",
    "    print(\"Acumulating\")\n",
    "    for i in range(1000):\n",
    "        data = itr.next()\n",
    "        grp = toGraphsTuple(data)\n",
    "        model.loss(grp, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1648712096483,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "zCL_h2riGcON",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dt2 = load_dataset(data_path, data_train)\n",
    "dt2 = add_targets(dt2, targets, add_history=params[0]['history'])\n",
    "qq = iter(dt2).next()\n",
    "qqq = {}\n",
    "for i, j in qq.items():\n",
    "    qqq[i] = j[0]\n",
    "grp_ = toGraphsTuple(qqq, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(), dtype=float32, numpy=0.91523933>,\n <tf.Tensor: shape=(), dtype=float32, numpy=1.6733382>,\n <tf.Tensor: shape=(), dtype=float32, numpy=44.354774>,\n <tf.Tensor: shape=(), dtype=float32, numpy=334.88293>,\n <tf.Tensor: shape=(), dtype=float32, numpy=68885.2>,\n <tf.Tensor: shape=(), dtype=float32, numpy=158172.36>)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(qqq['density']), tf.reduce_max(qqq['density']),tf.reduce_min(qqq['velocity'][0]), tf.reduce_max(qqq['velocity'][0]),tf.reduce_min(qqq['pressure']), tf.reduce_max(qqq['pressure'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1648712096485,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "n6-zse4oZlLr"
   },
   "outputs": [],
   "source": [
    "if \"m\" in locals():\n",
    "    m.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sdIk7J4Gn-Z"
   },
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1599,
     "status": "ok",
     "timestamp": 1648712098071,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "B7az1IQah3pZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res = [grp_, ]\n",
    "loss_mask = tf.logical_or(tf.equal(qqq['node_type'][:, 0], NodeType.NORMAL),\n",
    "                          tf.equal(qqq['node_type'][:, 0], NodeType.OUTFLOW))\n",
    "feat = grp_.nodes.shape\n",
    "loss_mask = tf.reshape(tf.concat([loss_mask for _ in range(grp_.nodes.shape[1])], -1), [-1, grp_.nodes.shape[1]])\n",
    "for i in range(600):\n",
    "    grp2_ = model(grp_, False)\n",
    "    grp_ = grp_.replace(nodes=tf.where(loss_mask, grp2_.nodes, grp_.nodes))\n",
    "    res.append(grp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648712098073,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "EewpBxU7HoZI"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def toGraphsTupleOld(d):\n",
    "    send, recive = triangles_to_edges(d['cells'])\n",
    "    rel_pos = (tf.gather(d['mesh_pos'], send) - tf.gather(d['mesh_pos'], recive))\n",
    "    nodes_unique = tf.unique_with_counts(tf.reshape(d[\"node_type\"], [-1]))\n",
    "    dd = {\n",
    "        #\"nodes\": tf.concat([d[\"velocity\"],d[\"pressure\"],d[\"density\"],tf.cast(d[\"node_type\"],tf.float32),d[\"mesh_pos\"]],1),\n",
    "        \"nodes\": tf.concat([d['velocity'], tf.one_hot(tf.reshape(d[\"node_type\"], [-1]), NodeTypeCnt, dtype=tf.float32)],\n",
    "                           1),  # on change update loss function ^\n",
    "        \"senders\": send,\n",
    "        \"receivers\": recive,\n",
    "        \"edges\": tf.concat([\n",
    "            rel_pos,\n",
    "            tf.norm(rel_pos, axis=-1, keepdims=True)], 1)\n",
    "    }\n",
    "    return utils_tf.data_dicts_to_graphs_tuple([dd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648712098074,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "W6HE1HO-paOC"
   },
   "outputs": [],
   "source": [
    "# fix mistake in data preparation\n",
    "if chck_root == \"models/new\":\n",
    "    grp_ = toGraphsTupleOld(qqq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 98452,
     "status": "ok",
     "timestamp": 1648712196517,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "iYsAa0I3E3E4"
   },
   "outputs": [],
   "source": [
    "res = [grp_, ]\n",
    "loss_mask = tf.logical_or(tf.equal(qqq['node_type'][:, 0], NodeType.NORMAL),\n",
    "                          tf.equal(qqq['node_type'][:, 0], NodeType.OUTFLOW))\n",
    "loss_mask = tf.reshape(tf.concat([loss_mask for _ in range(5)], -1), [-1, 5])\n",
    "for i in range(600):\n",
    "    grp2_ = model(grp_, False)\n",
    "    grp_ = grp_.replace(nodes=tf.where(loss_mask, grp2_.nodes, grp_.nodes))\n",
    "    res.append(grp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1648712196518,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "yAvHsrlrNR8Y",
    "outputId": "faaf7b8a-f5b1-448f-ea0a-44ae3c4f2419"
   },
   "outputs": [],
   "source": [
    "grp_.nodes.shape, grp2_.nodes.shape, loss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1648712196519,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "D_x92ZzOSIFR"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import tri as mtri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1648712196520,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "sojXwyPSCjPn",
    "outputId": "37314be2-5542-4c03-e51c-30b1feea8860"
   },
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1XBxHH8Si61fE5ZSFsgHWJbBS3IjjQEd0"
    },
    "id": "xD-mCoFaRV_r",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712260357,
     "user_tz": -120,
     "elapsed": 63379,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "outputId": "86d3de5c-6155-4bd1-c304-729b89550be4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "skip = 5\n",
    "num_steps = len(res)\n",
    "num_frames = num_steps // skip\n",
    "# compute bounds\n",
    "bounds = []\n",
    "bb_min, bb_max = tf.reduce_min(qq['velocity'][:, 0]), tf.reduce_max(qq['velocity'][:, 0])\n",
    "\n",
    "\n",
    "def animate(num):\n",
    "    global t\n",
    "    step = (num * skip) % num_steps\n",
    "    traj = (num * skip) // num_steps\n",
    "    ax.cla()\n",
    "    ax.set_xlim(-1, 2)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_autoscale_on(False)\n",
    "    vmin, vmax = bb_min, bb_max\n",
    "    pos = qqq['mesh_pos']\n",
    "    faces = qqq['cells']\n",
    "    velocity = res[step].nodes[..., :2].numpy()\n",
    "    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n",
    "    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax)\n",
    "    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n",
    "    ax.set_title('Trajectory %d Step %d' % (traj, step))\n",
    "    return fig,\n",
    "\n",
    "\n",
    "animate(0)\n",
    "plt.colorbar(t)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xAk5i42t-uik",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712320015,
     "user_tz": -120,
     "elapsed": 59668,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "outputId": "fb1d473a-9b96-4a8a-e2cd-d409ccf2d822"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "skip = 5\n",
    "num_steps = len(res)\n",
    "num_frames = num_steps // skip\n",
    "# compute bounds\n",
    "bounds = []\n",
    "\n",
    "bb_min, bb_max = tf.reduce_min(qq['velocity'][:, 0]), tf.reduce_max(qq['velocity'][:, 0])\n",
    "\n",
    "\n",
    "def animate(num):\n",
    "    global t\n",
    "    step = (num * skip) % num_steps\n",
    "    traj = (num * skip) // num_steps\n",
    "    ax.cla()\n",
    "    ax.set_xlim(-1, 2)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_autoscale_on(False)\n",
    "    vmin, vmax = bb_min, bb_max\n",
    "    pos = qq['mesh_pos'][0]\n",
    "    faces = qq['cells'][0]\n",
    "    velocity = qq['velocity'][step]\n",
    "    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n",
    "    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax)\n",
    "    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n",
    "    ax.set_title('Trajectory %d Step %d' % (traj, step))\n",
    "    return fig,\n",
    "\n",
    "\n",
    "animate(0)\n",
    "plt.colorbar(t)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "skip = 5\n",
    "num_steps = len(res)\n",
    "num_frames = num_steps // skip\n",
    "# compute bounds\n",
    "bounds = []\n",
    "\n",
    "bb_min, bb_max = 0, tf.reduce_max(qq['velocity'][:, 0])\n",
    "\n",
    "\n",
    "def animate(num):\n",
    "    global t\n",
    "    step = (num * skip) % num_steps\n",
    "    traj = (num * skip) // num_steps\n",
    "    ax.cla()\n",
    "    ax.set_xlim(-1, 2)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_autoscale_on(False)\n",
    "    vmin, vmax = bb_min, bb_max\n",
    "    pos = qq['mesh_pos'][0]\n",
    "    faces = qq['cells'][0]\n",
    "    velocity = tf.math.abs(qq['velocity'][step] - res[step].nodes[..., :2])\n",
    "    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n",
    "    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax, cmap='Reds')\n",
    "    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n",
    "    ax.set_title('Trajectory %d Step %d' % (traj, step))\n",
    "    return fig,\n",
    "\n",
    "\n",
    "animate(0)\n",
    "plt.colorbar(t)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ],
   "metadata": {
    "id": "k_531TOhTPL1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712380274,
     "user_tz": -120,
     "elapsed": 60277,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "13eecbed-f2b9-4bc1-dc12-d1160e260fdf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUC2kys8BVfb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712380275,
     "user_tz": -120,
     "elapsed": 39,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f2b904cb-399b-4561-96fa-5f2ae9ff4b8f"
   },
   "outputs": [],
   "source": [
    "bb_min, bb_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-1F-HpWKSJK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712380276,
     "user_tz": -120,
     "elapsed": 31,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e8ddb15-3bfc-4cb8-d8a7-847c5a1aa88d"
   },
   "outputs": [],
   "source": [
    "model._node_norm._std_with_epsilon(), model._node_norm._mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDos9sgYNAWO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712380277,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ad11eb9-e584-40e1-b24b-8a46c1281df2"
   },
   "outputs": [],
   "source": [
    "qq['target|velocity'].shape, qq['velocity'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te9-5ridMn9J",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712380278,
     "user_tz": -120,
     "elapsed": 19,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3c17b6a7-1f49-416b-ab08-349a1c00998e"
   },
   "outputs": [],
   "source": [
    "r = tf.reduce_sum((qq['velocity'] - qq['target|velocity']) ** 2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z54kK29oQqSF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712381589,
     "user_tz": -120,
     "elapsed": 1325,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "tt = [{i: qq[i][x] for i in qq.keys()} for x in range(599)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2Doz88iMIcF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712489942,
     "user_tz": -120,
     "elapsed": 108356,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "lss = []\n",
    "for i in tt:\n",
    "    lss.append(model.loss(toGraphsTuple(i), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-WgXhS0PoJ2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712489944,
     "user_tz": -120,
     "elapsed": 34,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "lss = [x.numpy() for x in lss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPMBBA--UGY5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712490357,
     "user_tz": -120,
     "elapsed": 444,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "outputId": "f675e1e4-71e7-4afa-b103-0e15b8f4b279"
   },
   "outputs": [],
   "source": [
    "plt.plot(lss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4Iw9fT7tSHry",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712490359,
     "user_tz": -120,
     "elapsed": 44,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a821351e-c1bc-4bd1-c499-d8a95ef4de1d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "1e7 / (1000 * 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nO_jH39ETn35",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712490361,
     "user_tz": -120,
     "elapsed": 34,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fa9794d0-d7bd-49ab-cfc5-a2d894b24a35"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2332162"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "ee = [x.shape.as_list() for x in model.trainable_variables]\n",
    "sum([(y[0] if len(y) == 1 else y[0] * y[1]) for y in ee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "p1KK9yuhWwXG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1648712490362,
     "user_tz": -120,
     "elapsed": 29,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "graph_lib.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}