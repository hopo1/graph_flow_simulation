{"cells":[{"cell_type":"markdown","metadata":{"id":"9REjiR7FxLky"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9uKD3smEvSec"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1648711983011,"user":{"displayName":"david horsky","userId":"15225206442244274917"},"user_tz":-120},"id":"SRn5zviK9mab","outputId":"0e97d487-6b1e-4634-ae2c-a353ac1e4440"},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["try:\n","    import google.colab\n","\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False\n","print(IN_COLAB)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5031,"status":"ok","timestamp":1648711988032,"user":{"displayName":"david horsky","userId":"15225206442244274917"},"user_tz":-120},"id":"F8Gbla5EAnuT","outputId":"62ae1b95-2a71-46eb-f610-9874754e00b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: graph_nets in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.0)\n","Requirement already satisfied: dm-sonnet in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.0)\n","Requirement already satisfied: tensorflow_probability in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.16.0)\n","Requirement already satisfied: dm-tree in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (0.1.6)\n","Requirement already satisfied: networkx in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (2.6.3)\n","Requirement already satisfied: future in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (0.18.2)\n","Requirement already satisfied: numpy in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.22.2)\n","Requirement already satisfied: six in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.16.0)\n","Requirement already satisfied: setuptools in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (57.4.0)\n","Requirement already satisfied: absl-py in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.0.0)\n","Requirement already satisfied: tabulate>=0.7.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-sonnet) (0.8.9)\n","Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-sonnet) (1.13.3)\n","Requirement already satisfied: gast>=0.3.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (0.5.3)\n","Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (2.0.0)\n","Requirement already satisfied: decorator in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n","You should consider upgrading via the 'C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["!pip install graph_nets  dm-sonnet tensorflow_probability"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmcb7EBvvoyF"},"outputs":[],"source":["if IN_COLAB and 'drive' not in os.listdir(\"/content\"):\n","    from google.colab import drive\n","\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSW2Lvxg86fC"},"outputs":[],"source":["if IN_COLAB:\n","    os.chdir('/content/drive/MyDrive/bakalarka')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VciOHpBLwvLT","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import tensorflow as tf\n","\n","import time\n","import sys\n","import re\n","\n","from graph_nets import utils_tf\n"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from EncodeProcessDecodeBasic import EncodeProcessDecode\n","from EncodeProcessDecodeNorm import EncodeProcessDecode as EncodeProcessDecodeNorm\n","from EncodeProcessDecodeAddNorm import EncodeProcessDecode as EncodeProcessDecodeAddNorm\n","from EncodeProcessDecodeNoLib import EncodeProcessDecode as EncodeProcessDecodeNoLib\n","from EncodeProcessDecodeMultinet import EncodeProcessDecode as EncodeProcessDecodeMultinet\n","from EncodeProcessDecodeNamedMultinet import EncodeProcessDecode as EncodeProcessDecodeNamedMultinet"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"JLR0hCSEHdV5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["tf.config.run_functions_eagerly(True)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"MkyPFOXRHdV6"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["mod = \"named-full\"\n","models = {\"basic\": {\"model\": EncodeProcessDecode,\n","                    \"args\": {\"steps\": 15,\n","                             \"learn_features\": 2,\n","                             \"node_net_sizes\": [128] * 2 + [2],\n","                             \"edge_net_sizes\": [128] * 2 + [4]},\n","                    \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                    size=2, batch=1)]},\n","          \"small_test\": {\"model\": EncodeProcessDecode,\n","                         \"args\": {\"steps\": 5,\n","                                  \"learn_features\": 2,\n","                                  \"node_net_sizes\": [8] * 2 + [2],\n","                                  \"edge_net_sizes\": [8] * 2 + [4]},\n","                         \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                         size=2, batch=1)]},\n","          \"full\": {\"model\": EncodeProcessDecodeNorm,\n","                   \"args\": {\"steps\": 15,\n","                            \"learn_features\": 2,\n","                            \"n_layers\": 2,\n","                            \"lat_size\": 128,\n","                            \"edge_feat_cnt\": 3,\n","                            \"node_feat_cnt\": 5},\n","                   \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                   size=2, batch=1)]},\n","          \"no-norm\": {\"model\": EncodeProcessDecodeNorm,\n","                      \"args\": {\"steps\": 15,\n","                               \"learn_features\": 2,\n","                               \"n_layers\": 2,\n","                               \"lat_size\": 128,\n","                               \"edge_feat_cnt\": 3,\n","                               \"node_feat_cnt\": 5,\n","                               \"la_norm\": False},\n","                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                      size=2, batch=1)]},\n","          \"add\": {\"model\": EncodeProcessDecodeAddNorm,\n","                  \"args\": {\"steps\": 15,\n","                           \"learn_features\": 2,\n","                           \"n_layers\": 2,\n","                           \"lat_size\": 128,\n","                           \"edge_feat_cnt\": 3,\n","                           \"node_feat_cnt\": 5},\n","                  \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                  size=2, batch=1)]},\n","          \"no-lib\": {\"model\": EncodeProcessDecodeNoLib,\n","                     \"args\": {\"steps\": 15,\n","                              \"learn_features\": 2,\n","                              \"n_layers\": 2,\n","                              \"lat_size\": 128,\n","                              \"edge_feat_cnt\": 3,\n","                              \"node_feat_cnt\": 5},\n","                     \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                     size=2, batch=1)]},\n","          \"multinet\": {\"model\": EncodeProcessDecodeMultinet,\n","                       \"args\": {\"steps\": 15,\n","                                \"learn_features\": 2,\n","                                \"n_layers\": 2,\n","                                \"lat_size\": 128,\n","                                \"edge_feat_cnt\": 3,\n","                                \"node_feat_cnt\": 5},\n","                       \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                       size=2, batch=2)]},\n","          \"named\": {\"model\": EncodeProcessDecodeNamedMultinet,\n","                    \"args\": {\"steps\": 15,\n","                             \"learn_features\": 2,\n","                             \"n_layers\": 2,\n","                             \"lat_size\": 128,\n","                             \"edge_feat_cnt\": 3,\n","                             \"node_feat_cnt\": 5},\n","                    \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                    size=2, batch=2)]},\n","          \"named18\": {\"model\": EncodeProcessDecodeNamedMultinet,\n","                      \"args\": {\"steps\": 18,\n","                               \"learn_features\": 2,\n","                               \"n_layers\": 2,\n","                               \"lat_size\": 128,\n","                               \"edge_feat_cnt\": 3,\n","                               \"node_feat_cnt\": 5},\n","                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                      size=2, batch=2)]},\n","          \"named12\": {\"model\": EncodeProcessDecodeNamedMultinet,\n","                      \"args\": {\"steps\": 12,\n","                               \"learn_features\": 2,\n","                               \"n_layers\": 2,\n","                               \"lat_size\": 128,\n","                               \"edge_feat_cnt\": 3,\n","                               \"node_feat_cnt\": 5},\n","                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                      size=2, batch=2)]},\n","          \"named-full\": {\"model\": EncodeProcessDecodeNamedMultinet,\n","                         \"args\": {\"steps\": 12,\n","                                  \"learn_features\": 4,\n","                                  \"n_layers\": 2,\n","                                  \"lat_size\": 128,\n","                                  \"edge_feat_cnt\": 3,\n","                                  \"node_feat_cnt\": 7},\n","                         \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n","                                         size=2, batch=2),\n","                                    dict(noise=0.02, gamma=1.0, field='pressure', history=False,\n","                                         size=1, batch=2),\n","                                    dict(noise=0.02, gamma=1.0, field='density', history=False,\n","                                         size=1, batch=2)]},\n","          \"named15n\": {\"model\": EncodeProcessDecodeNamedMultinet,\n","                    \"args\": {\"steps\": 12,\n","                             \"learn_features\": 2,\n","                             \"n_layers\": 2,\n","                             \"lat_size\": 128,\n","                             \"edge_feat_cnt\": 3,\n","                             \"node_feat_cnt\": 5},\n","                    \"params\": [dict(noise=1.0, gamma=1.0, field='velocity', history=False,\n","                                    size=2, batch=2)]}}"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Yz-PFzUjHdV6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaXyDwZGx59F","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["params = models[mod][\"params\"]\n","targets = tuple([x[\"field\"] for x in params])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_na6wHrgyG8F"},"outputs":[],"source":["from common import NodeType"]},{"cell_type":"markdown","metadata":{"id":"tVLsMSLjxSQz"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FYCTQTvKxrOv"},"outputs":[],"source":["data_path = 'data/airfoil'\n","data_train = 'small' if IN_COLAB else 'train'\n","data_valid = 'small' if IN_COLAB else 'valid'\n","data_test = 'small' if IN_COLAB else 'test'"]},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from dataset import load_dataset, split_dataset, prepare, add_noises, add_targets, add_batch, triangles_to_edges"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"KKLDvDSlHdV-"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]}],"source":["ds = load_dataset(data_path, data_train)\n","ds = add_targets(ds, targets, add_history=params[0]['history'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"q90jpU23HdV-","outputId":"5abe00f2-cbe5-4c66-e47a-c2f97bc8c7fb"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["ds = split_dataset(ds)\n","for param in params:\n","    ds = add_noises(ds, noise_field=param['field'],\n","                    noise_scale=param['noise'],\n","                    noise_gamma=param['gamma'])\n","ds = prepare(ds, 100 if IN_COLAB else 10000)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"19tJ1G2nHdV-"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["ds = add_batch(ds, params[0]['batch'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"vl5V1pwbHdV-"}},{"cell_type":"markdown","source":["## Prepare for learning"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"IatR7S-eHdV_"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["itr = iter(ds)\n","d = itr.next()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"gUOIXqMTHdV_"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["NodeTypeCnt = tf.unique(tf.reshape(d['node_type'], d['node_type'].shape[:1])).y.shape[0]"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"JKh7B-ULHdV_"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["@tf.function\n","def toGraphsTuple(d, targets=('velocity',)):\n","    send, recive = triangles_to_edges(d['cells'])\n","    rel_pos = (tf.gather(d['mesh_pos'], send) - tf.gather(d['mesh_pos'], recive))\n","    nodes_unique = tf.unique_with_counts(tf.reshape(d[\"node_type\"], [-1]))\n","    one_hot = tf.one_hot(nodes_unique.idx, NodeTypeCnt, dtype=tf.float32)\n","    dd = {\n","        \"nodes\": tf.concat([*[d[x] for x in targets], one_hot], 1),\n","        # on change update loss function ^\n","        \"senders\": send,\n","        \"receivers\": recive,\n","        \"edges\": tf.concat([\n","            rel_pos,\n","            tf.norm(rel_pos, axis=-1, keepdims=True)], 1)\n","    }\n","    return utils_tf.data_dicts_to_graphs_tuple([dd])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"HNYzuTtLHdV_"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["dd = toGraphsTuple(d, targets)\n","LINEAR_FEATURES = dd.nodes.shape[1] - NodeTypeCnt"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FLILaebWHdV_"}},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"GraphsTuple(nodes=<tf.Tensor: shape=(10466, 5), dtype=float32, numpy=\narray([[131.9859  ,  20.154928,   1.      ,   0.      ,   0.      ],\n       [151.5147  ,  21.275198,   1.      ,   0.      ,   0.      ],\n       [162.18492 ,  23.188953,   1.      ,   0.      ,   0.      ],\n       ...,\n       [ 87.38186 , -25.509438,   0.      ,   0.      ,   1.      ],\n       [ 87.445595, -25.126059,   0.      ,   0.      ,   1.      ],\n       [ 87.46395 , -25.380064,   0.      ,   0.      ,   1.      ]],\n      dtype=float32)>, edges=<tf.Tensor: shape=(61796, 3), dtype=float32, numpy=\narray([[ 0.00579996, -0.01206488,  0.01338659],\n       [-0.00720367, -0.01440071,  0.01610196],\n       [-0.00630522,  0.0145334 ,  0.0158422 ],\n       ...,\n       [ 0.30951977,  1.4802246 ,  1.5122392 ],\n       [ 1.0828505 ,  1.8325498 ,  2.1285684 ],\n       [-0.43042946,  1.2830333 ,  1.3533084 ]], dtype=float32)>, receivers=<tf.Tensor: shape=(61796,), dtype=int32, numpy=array([   69,    55,   159, ..., 10294, 10339, 10342])>, senders=<tf.Tensor: shape=(61796,), dtype=int32, numpy=array([  417,   302,   405, ..., 10262, 10330, 10308])>, globals=None, n_node=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([10466])>, n_edge=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([61796])>)"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["dd"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ZELBPJo9HdV_","outputId":"13b031fd-35ac-45f7-b24b-48fd68cf4cf5"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["aa = itr.next()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ftaOfO9THdWA"}},{"cell_type":"markdown","source":["## Model and loss function"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"Fz9K_I7BHdWA"}},{"cell_type":"markdown","source":["### Model hyperparameters"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"YMFSgfUTHdWA"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from AdamModLr import Adam\n","\n","lr = 1e-4\n","# opt = snt.optimizers.Adam(lr)\n","opt = Adam(lr)\n","steps = 15\n","#model = EncodeProcessDecode(steps, LINEAR_FEATURES, [128] * 2, [128] * 2 + [4])\n","md = models[mod]\n","model = md[\"model\"](**md[\"args\"])\n","initial_learning_rate = lr\n","decay_rate = 0.1\n","decay_steps = 5e6\n","learning_increase = 1e-6"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"PZluLMdnHdWA"}},{"cell_type":"markdown","source":["## Training"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"Tzjraw3uHdWA"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def decayed_learning_rate(step):\n","    return initial_learning_rate * decay_rate ** (step / decay_steps) + learning_increase"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"P79gZbRZHdWA"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["@tf.function\n","def update_step(data, targets=('velocity')):\n","    print(\"Tracing!\")\n","    grp = toGraphsTuple(data, targets)\n","    with tf.GradientTape() as tape:\n","        los = model.loss(grp, data)  #change to loss\n","\n","    gradients = tape.gradient(los, model.trainable_variables)\n","\n","    opt.apply(gradients, model.trainable_variables)\n","    return los"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"AAqw9k3eHdWA"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Tracing!\n","Tracing!\n"]}],"source":["update_step(aa, targets);"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"-4qTKGymHdWB","outputId":"9bbc9461-f9a9-4a57-b2a6-65c122bb55a7"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["@tf.function\n","def loss(grp, data):\n","    return model.loss(grp, data)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QZcvGE-RHdWB"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["if IN_COLAB:\n","    logdir = 'logs/tst/'\n","    writer = tf.summary.create_file_writer(logdir)\n","\n","    # Bracket the function call with\n","    # tf.summary.trace_on() and tf.summary.trace_export().\n","    tf.summary.trace_on(graph=True, profiler=True)\n","    # Call only one tf.function when tracing.\n","    z = loss(dd, d)\n","    with writer.as_default():\n","        tf.summary.trace_export(\n","            name=\"my_func_trace\",\n","            step=0,\n","            profiler_outdir=logdir)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"GzW26RrwHdWB"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["loading models/namednet/named-197\n"]}],"source":["chck_root = \"models/namednet/\"\n","chck_name = mod\n","\n","chck = tf.train.Checkpoint(module=model)\n","\n","latest = tf.train.latest_checkpoint(chck_root)\n","if latest is not None:\n","    print(\"loading\", latest)\n","    chck.restore(latest)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"shX4Owf0HdWB","outputId":"bc2baa33-d2de-4dee-dd91-90bbec0828d2"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["if latest is None and not isinstance(model, EncodeProcessDecode):\n","    print(\"Acumulating\")\n","    for i in range(1000):\n","        data = itr.next()\n","        grp = toGraphsTuple(data, targets)\n","        model.loss(grp, data)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"t4dUioYLHdWB"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["training\n","i 7880000 mse: 0.10028864\n"]}],"source":["colab_train = False\n","start = 0\n","sm_print = 500\n","save_itr = 40000\n","if not IN_COLAB or colab_train:\n","    if latest is not None:\n","        start = int(re.findall('\\d+$', latest)[0]) * save_itr\n","    t = time.time()\n","    print(\"training\")\n","    sys.stdout.flush()\n","    for i in range(start, int(1e7) + 1):\n","        a = itr.next()\n","        m = update_step(a, targets)\n","        if i % sm_print == 0:\n","            opt.learning_rate.assign(decayed_learning_rate(i))\n","            print(\"i\", i, \"mse:\", m.numpy())\n","            if i and i % save_itr == 0:\n","                sys.stdout.flush()\n","                chck.save(chck_root + chck_name)\n","    print(time.time() - t)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"PDSYbt-RHdWB","outputId":"be3ab5c1-e96e-40d3-addd-94f857c61ad6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"F4Xnsg7MpzaY"},"outputs":[],"source":["chck_root = \"models/namednet/\"\n","chck_name = mod\n","\n","chck = tf.train.Checkpoint(module=model)\n","\n","latest = tf.train.latest_checkpoint(chck_root)\n","if latest is not None:\n","    print(\"loading\", latest)\n","    chck.restore(latest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgZu39MbJi_z"},"outputs":[],"source":["if latest is None and not isinstance(model, EncodeProcessDecode):\n","    print(\"Acumulating\")\n","    for i in range(1000):\n","        data = itr.next()\n","        grp = toGraphsTuple(data)\n","        model.loss(grp, data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zCL_h2riGcON","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["dt2 = load_dataset(data_path, data_train)\n","dt2 = add_targets(dt2, targets, add_history=params[0]['history'])\n","qq = iter(dt2).next()\n","qqq = {}\n","for i, j in qq.items():\n","    qqq[i] = j[0]\n","grp_ = toGraphsTuple(qqq, targets)"]},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"(<tf.Tensor: shape=(), dtype=float32, numpy=0.91523933>,\n <tf.Tensor: shape=(), dtype=float32, numpy=1.6733382>,\n <tf.Tensor: shape=(), dtype=float32, numpy=44.354774>,\n <tf.Tensor: shape=(), dtype=float32, numpy=334.88293>,\n <tf.Tensor: shape=(), dtype=float32, numpy=68885.2>,\n <tf.Tensor: shape=(), dtype=float32, numpy=158172.36>)"},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["tf.reduce_min(qqq['density']), tf.reduce_max(qqq['density']),tf.reduce_min(qqq['velocity'][0]), tf.reduce_max(qqq['velocity'][0]),tf.reduce_min(qqq['pressure']), tf.reduce_max(qqq['pressure'])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rxl7B_NWHdWC","outputId":"381d9440-009c-45e7-bcad-9f56afbbfbce"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6-zse4oZlLr"},"outputs":[],"source":["if \"m\" in locals():\n","    m.numpy()"]},{"cell_type":"markdown","metadata":{"id":"2sdIk7J4Gn-Z"},"source":["## Vizualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7az1IQah3pZ","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["res = [grp_, ]\n","loss_mask = tf.logical_or(tf.equal(qqq['node_type'][:, 0], NodeType.NORMAL),\n","                          tf.equal(qqq['node_type'][:, 0], NodeType.OUTFLOW))\n","feat = grp_.nodes.shape\n","loss_mask = tf.reshape(tf.concat([loss_mask for _ in range(grp_.nodes.shape[1])], -1), [-1, grp_.nodes.shape[1]])\n","for i in range(600):\n","    grp2_ = model(grp_, False)\n","    grp_ = grp_.replace(nodes=tf.where(loss_mask, grp2_.nodes, grp_.nodes))\n","    res.append(grp_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EewpBxU7HoZI"},"outputs":[],"source":["@tf.function\n","def toGraphsTupleOld(d):\n","    send, recive = triangles_to_edges(d['cells'])\n","    rel_pos = (tf.gather(d['mesh_pos'], send) - tf.gather(d['mesh_pos'], recive))\n","    nodes_unique = tf.unique_with_counts(tf.reshape(d[\"node_type\"], [-1]))\n","    dd = {\n","        #\"nodes\": tf.concat([d[\"velocity\"],d[\"pressure\"],d[\"density\"],tf.cast(d[\"node_type\"],tf.float32),d[\"mesh_pos\"]],1),\n","        \"nodes\": tf.concat([d['velocity'], tf.one_hot(tf.reshape(d[\"node_type\"], [-1]), NodeTypeCnt, dtype=tf.float32)],\n","                           1),  # on change update loss function ^\n","        \"senders\": send,\n","        \"receivers\": recive,\n","        \"edges\": tf.concat([\n","            rel_pos,\n","            tf.norm(rel_pos, axis=-1, keepdims=True)], 1)\n","    }\n","    return utils_tf.data_dicts_to_graphs_tuple([dd])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6HE1HO-paOC"},"outputs":[],"source":["# fix mistake in data preparation\n","if chck_root == \"models/new\":\n","    grp_ = toGraphsTupleOld(qqq)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYsAa0I3E3E4"},"outputs":[],"source":["res = [grp_, ]\n","loss_mask = tf.logical_or(tf.equal(qqq['node_type'][:, 0], NodeType.NORMAL),\n","                          tf.equal(qqq['node_type'][:, 0], NodeType.OUTFLOW))\n","loss_mask = tf.reshape(tf.concat([loss_mask for _ in range(5)], -1), [-1, 5])\n","for i in range(600):\n","    grp2_ = model(grp_, False)\n","    grp_ = grp_.replace(nodes=tf.where(loss_mask, grp2_.nodes, grp_.nodes))\n","    res.append(grp_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAvHsrlrNR8Y"},"outputs":[],"source":["grp_.nodes.shape, grp2_.nodes.shape, loss_mask.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D_x92ZzOSIFR"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","from matplotlib import tri as mtri"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sojXwyPSCjPn"},"outputs":[],"source":["res[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xD-mCoFaRV_r","executionInfo":{"status":"ok","timestamp":1648712260357,"user_tz":-120,"elapsed":63379,"user":{"displayName":"david horsky","userId":"15225206442244274917"}},"outputId":"86d3de5c-6155-4bd1-c304-729b89550be4"},"outputs":[],"source":["fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","skip = 5\n","num_steps = len(res)\n","num_frames = num_steps // skip\n","# compute bounds\n","bounds = []\n","bb_min, bb_max = tf.reduce_min(qq['velocity'][:, 0]), tf.reduce_max(qq['velocity'][:, 0])\n","\n","\n","def animate(num):\n","    global t\n","    step = (num * skip) % num_steps\n","    traj = (num * skip) // num_steps\n","    ax.cla()\n","    ax.set_xlim(-1, 2)\n","    ax.set_ylim(-1.5, 1.5)\n","    ax.set_autoscale_on(False)\n","    vmin, vmax = bb_min, bb_max\n","    pos = qqq['mesh_pos']\n","    faces = qqq['cells']\n","    velocity = res[step].nodes[..., :2].numpy()\n","    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n","    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax)\n","    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n","    ax.set_title('Trajectory %d Step %d' % (traj, step))\n","    return fig,\n","\n","\n","animate(0)\n","plt.colorbar(t)\n","\n","anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n","from IPython.display import HTML\n","\n","HTML(anim.to_html5_video())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAk5i42t-uik"},"outputs":[],"source":["fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","skip = 5\n","num_steps = len(res)\n","num_frames = num_steps // skip\n","# compute bounds\n","bounds = []\n","\n","bb_min, bb_max = tf.reduce_min(qq['velocity'][:, 0]), tf.reduce_max(qq['velocity'][:, 0])\n","\n","\n","def animate(num):\n","    global t\n","    step = (num * skip) % num_steps\n","    traj = (num * skip) // num_steps\n","    ax.cla()\n","    ax.set_xlim(-1, 2)\n","    ax.set_ylim(-1.5, 1.5)\n","    ax.set_autoscale_on(False)\n","    vmin, vmax = bb_min, bb_max\n","    pos = qq['mesh_pos'][0]\n","    faces = qq['cells'][0]\n","    velocity = qq['velocity'][step]\n","    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n","    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax)\n","    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n","    ax.set_title('Trajectory %d Step %d' % (traj, step))\n","    return fig,\n","\n","\n","animate(0)\n","plt.colorbar(t)\n","\n","anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n","from IPython.display import HTML\n","\n","HTML(anim.to_html5_video())"]},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","skip = 5\n","num_steps = len(res)\n","num_frames = num_steps // skip\n","# compute bounds\n","bounds = []\n","\n","bb_min, bb_max = 0, tf.reduce_max(qq['velocity'][:, 0])\n","\n","\n","def animate(num):\n","    global t\n","    step = (num * skip) % num_steps\n","    traj = (num * skip) // num_steps\n","    ax.cla()\n","    ax.set_xlim(-1, 2)\n","    ax.set_ylim(-1.5, 1.5)\n","    ax.set_autoscale_on(False)\n","    vmin, vmax = bb_min, bb_max\n","    pos = qq['mesh_pos'][0]\n","    faces = qq['cells'][0]\n","    velocity = tf.math.abs(qq['velocity'][step] - res[step].nodes[..., :2])\n","    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n","    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax, cmap='Reds')\n","    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n","    ax.set_title('Trajectory %d Step %d' % (traj, step))\n","    return fig,\n","\n","\n","animate(0)\n","plt.colorbar(t)\n","\n","anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n","from IPython.display import HTML\n","\n","HTML(anim.to_html5_video())"],"metadata":{"id":"k_531TOhTPL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUC2kys8BVfb"},"outputs":[],"source":["bb_min, bb_max"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-1F-HpWKSJK"},"outputs":[],"source":["model._node_norm._std_with_epsilon(), model._node_norm._mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDos9sgYNAWO"},"outputs":[],"source":["qq['target|velocity'].shape, qq['velocity'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Te9-5ridMn9J"},"outputs":[],"source":["r = tf.reduce_sum((qq['velocity'] - qq['target|velocity']) ** 2)\n","r"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z54kK29oQqSF"},"outputs":[],"source":["tt = [{i: qq[i][x] for i in qq.keys()} for x in range(599)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2Doz88iMIcF"},"outputs":[],"source":["lss = []\n","for i in tt:\n","    lss.append(model.loss(toGraphsTuple(i), i))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-WgXhS0PoJ2"},"outputs":[],"source":["lss = [x.numpy() for x in lss]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TPMBBA--UGY5"},"outputs":[],"source":["plt.plot(lss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Iw9fT7tSHry","executionInfo":{"status":"ok","timestamp":1648712490359,"user_tz":-120,"elapsed":44,"user":{"displayName":"david horsky","userId":"15225206442244274917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a821351e-c1bc-4bd1-c499-d8a95ef4de1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["16.666666666666668"]},"metadata":{},"execution_count":61}],"source":["1e7 / (1000 * 600)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nO_jH39ETn35","executionInfo":{"status":"ok","timestamp":1648712490361,"user_tz":-120,"elapsed":34,"user":{"displayName":"david horsky","userId":"15225206442244274917"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa9794d0-d7bd-49ab-cfc5-a2d894b24a35"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2332162"]},"metadata":{},"execution_count":62}],"source":["ee = [x.shape.as_list() for x in model.trainable_variables]\n","sum([(y[0] if len(y) == 1 else y[0] * y[1]) for y in ee])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1KK9yuhWwXG"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"graph_lib.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}