{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9REjiR7FxLky"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9uKD3smEvSec",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651004805842,
     "user_tz": -120,
     "elapsed": 827,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651004806672,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "SRn5zviK9mab",
    "outputId": "77b21be1-919b-4048-f61a-16e2c3c49300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "print(IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5215,
     "status": "ok",
     "timestamp": 1651004811883,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     },
     "user_tz": -120
    },
    "id": "F8Gbla5EAnuT",
    "outputId": "cc230616-3aeb-4fca-9973-d2960244de0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graph_nets in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: dm-sonnet in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: tensorflow_probability in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (2.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (57.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.22.2)\n",
      "Requirement already satisfied: future in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (0.18.2)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (0.1.6)\n",
      "Requirement already satisfied: six in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.16.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from graph_nets) (1.0.0)\n",
      "Requirement already satisfied: tabulate>=0.7.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-sonnet) (0.8.9)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dm-sonnet) (1.13.3)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (0.5.3)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (2.0.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\david\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install graph_nets  dm-sonnet tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dmcb7EBvvoyF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651004832895,
     "user_tz": -120,
     "elapsed": 21020,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "outputId": "49bd5eb1-6a91-4a69-cfa9-a2dfca95abde"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB and 'drive' not in os.listdir(\"/content\"):\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kSW2Lvxg86fC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651004832897,
     "user_tz": -120,
     "elapsed": 8,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    os.chdir('/content/drive/MyDrive/bakalarka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VciOHpBLwvLT",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651004836931,
     "user_tz": -120,
     "elapsed": 4041,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from graph_nets import utils_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from EncodeProcessDecodeBasic import EncodeProcessDecode\n",
    "from EncodeProcessDecodeNorm import EncodeProcessDecode as EncodeProcessDecodeNorm\n",
    "from EncodeProcessDecodeAddNorm import EncodeProcessDecode as EncodeProcessDecodeAddNorm\n",
    "from EncodeProcessDecodeNoLib import EncodeProcessDecode as EncodeProcessDecodeNoLib\n",
    "from EncodeProcessDecodeMultinet import EncodeProcessDecode as EncodeProcessDecodeMultinet\n",
    "from EncodeProcessDecodeNamedMultinet import EncodeProcessDecode as EncodeProcessDecodeNamedMultinet"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "JLR0hCSEHdV5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1651004839059,
     "user_tz": -120,
     "elapsed": 2152,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "mod = \"named-full\"\n",
    "models = {\"basic\": {\"model\": EncodeProcessDecode,\n",
    "                    \"args\": {\"steps\": 15,\n",
    "                             \"learn_features\": 2,\n",
    "                             \"node_net_sizes\": [128] * 2 + [2],\n",
    "                             \"edge_net_sizes\": [128] * 2 + [4]},\n",
    "                    \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                    size=2, batch=1)]},\n",
    "          \"small_test\": {\"model\": EncodeProcessDecode,\n",
    "                         \"args\": {\"steps\": 5,\n",
    "                                  \"learn_features\": 2,\n",
    "                                  \"node_net_sizes\": [8] * 2 + [2],\n",
    "                                  \"edge_net_sizes\": [8] * 2 + [4]},\n",
    "                         \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                         size=2, batch=1)]},\n",
    "          \"full\": {\"model\": EncodeProcessDecodeNorm,\n",
    "                   \"args\": {\"steps\": 15,\n",
    "                            \"learn_features\": 2,\n",
    "                            \"n_layers\": 2,\n",
    "                            \"lat_size\": 128,\n",
    "                            \"edge_feat_cnt\": 3,\n",
    "                            \"node_feat_cnt\": 5},\n",
    "                   \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                   size=2, batch=1)]},\n",
    "          \"no-norm\": {\"model\": EncodeProcessDecodeNorm,\n",
    "                      \"args\": {\"steps\": 15,\n",
    "                               \"learn_features\": 2,\n",
    "                               \"n_layers\": 2,\n",
    "                               \"lat_size\": 128,\n",
    "                               \"edge_feat_cnt\": 3,\n",
    "                               \"node_feat_cnt\": 5,\n",
    "                               \"la_norm\": False},\n",
    "                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                      size=2, batch=1)]},\n",
    "          \"add\": {\"model\": EncodeProcessDecodeAddNorm,\n",
    "                  \"args\": {\"steps\": 15,\n",
    "                           \"learn_features\": 2,\n",
    "                           \"n_layers\": 2,\n",
    "                           \"lat_size\": 128,\n",
    "                           \"edge_feat_cnt\": 3,\n",
    "                           \"node_feat_cnt\": 5},\n",
    "                  \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                  size=2, batch=1)]},\n",
    "          \"no-lib\": {\"model\": EncodeProcessDecodeNoLib,\n",
    "                     \"args\": {\"steps\": 15,\n",
    "                              \"learn_features\": 2,\n",
    "                              \"n_layers\": 2,\n",
    "                              \"lat_size\": 128,\n",
    "                              \"edge_feat_cnt\": 3,\n",
    "                              \"node_feat_cnt\": 5},\n",
    "                     \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                     size=2, batch=1)]},\n",
    "          \"multinet\": {\"model\": EncodeProcessDecodeMultinet,\n",
    "                       \"args\": {\"steps\": 15,\n",
    "                                \"learn_features\": 2,\n",
    "                                \"n_layers\": 2,\n",
    "                                \"lat_size\": 128,\n",
    "                                \"edge_feat_cnt\": 3,\n",
    "                                \"node_feat_cnt\": 5},\n",
    "                       \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                       size=2, batch=2)]},\n",
    "          \"named\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                    \"args\": {\"steps\": 15,\n",
    "                             \"learn_features\": 2,\n",
    "                             \"n_layers\": 2,\n",
    "                             \"lat_size\": 128,\n",
    "                             \"edge_feat_cnt\": 3,\n",
    "                             \"node_feat_cnt\": 5},\n",
    "                    \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                    size=2, batch=2)]},\n",
    "          \"named18\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                      \"args\": {\"steps\": 18,\n",
    "                               \"learn_features\": 2,\n",
    "                               \"n_layers\": 2,\n",
    "                               \"lat_size\": 128,\n",
    "                               \"edge_feat_cnt\": 3,\n",
    "                               \"node_feat_cnt\": 5},\n",
    "                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                      size=2, batch=2)]},\n",
    "          \"named12\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                      \"args\": {\"steps\": 12,\n",
    "                               \"learn_features\": 2,\n",
    "                               \"n_layers\": 2,\n",
    "                               \"lat_size\": 128,\n",
    "                               \"edge_feat_cnt\": 3,\n",
    "                               \"node_feat_cnt\": 5},\n",
    "                      \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                      size=2, batch=2)]},\n",
    "          \"named-full\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                         \"args\": {\"steps\": 12,\n",
    "                                  \"learn_features\": 4,\n",
    "                                  \"n_layers\": 2,\n",
    "                                  \"lat_size\": 128,\n",
    "                                  \"edge_feat_cnt\": 3,\n",
    "                                  \"node_feat_cnt\": 7},\n",
    "                         \"params\": [dict(noise=0.02, gamma=1.0, field='velocity', history=False,\n",
    "                                         size=2, batch=2),\n",
    "                                    dict(noise=0.02, gamma=1.0, field='pressure', history=False,\n",
    "                                         size=1, batch=2),\n",
    "                                    dict(noise=0.02, gamma=1.0, field='density', history=False,\n",
    "                                         size=1, batch=2)]},\n",
    "          \"named12n\": {\"model\": EncodeProcessDecodeNamedMultinet,\n",
    "                    \"args\": {\"steps\": 12,\n",
    "                             \"learn_features\": 2,\n",
    "                             \"n_layers\": 2,\n",
    "                             \"lat_size\": 128,\n",
    "                             \"edge_feat_cnt\": 3,\n",
    "                             \"node_feat_cnt\": 5},\n",
    "                    \"params\": [dict(noise=1.0, gamma=1.0, field='velocity', history=False,\n",
    "                                    size=2, batch=2)]}}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "params = models[mod][\"params\"]\n",
    "targets = tuple([x[\"field\"] for x in params])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from common import NodeType"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data_path = 'data/airfoil'\n",
    "data_train = 'small' if IN_COLAB else 'train'\n",
    "data_valid = 'small' if IN_COLAB else 'valid'\n",
    "data_test = 'small' if IN_COLAB else 'test'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from dataset import load_dataset, split_dataset, prepare, add_noises, add_targets, add_batch, triangles_to_edges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "ds = load_dataset(data_path, data_train)\n",
    "ds = add_targets(ds, targets, add_history=params[0]['history'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ds = split_dataset(ds)\n",
    "for param in params:\n",
    "    ds = add_noises(ds, noise_field=param['field'],\n",
    "                    noise_scale=param['noise'],\n",
    "                    noise_gamma=param['gamma'])\n",
    "ds = prepare(ds, 100 if IN_COLAB else 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "ds = add_batch(ds, params[0]['batch'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare for learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "itr = iter(ds)\n",
    "d = itr.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "NodeTypeCnt = tf.unique(tf.reshape(d['node_type'], d['node_type'].shape[:1])).y.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def toGraphsTuple(d, targets=('velocity',)):\n",
    "    send, recive = triangles_to_edges(d['cells'])\n",
    "    rel_pos = (tf.gather(d['mesh_pos'], send) - tf.gather(d['mesh_pos'], recive))\n",
    "    nodes_unique = tf.unique_with_counts(tf.reshape(d[\"node_type\"], [-1]))\n",
    "    one_hot = tf.one_hot(nodes_unique.idx, NodeTypeCnt, dtype=tf.float32)\n",
    "    dd = {\n",
    "        \"nodes\": tf.concat([*[d[x] for x in targets], one_hot], 1),\n",
    "        # on change update loss function ^\n",
    "        \"senders\": send,\n",
    "        \"receivers\": recive,\n",
    "        \"edges\": tf.concat([\n",
    "            rel_pos,\n",
    "            tf.norm(rel_pos, axis=-1, keepdims=True)], 1)\n",
    "    }\n",
    "    return utils_tf.data_dicts_to_graphs_tuple([dd])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "dd = toGraphsTuple(d, targets)\n",
    "LINEAR_FEATURES = dd.nodes.shape[1] - NodeTypeCnt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "GraphsTuple(nodes=<tf.Tensor: shape=(10466, 7), dtype=float32, numpy=\narray([[6.54558029e+01, 8.08514023e+00, 1.04077398e+05, ...,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [7.33669281e+01, 1.03619909e+01, 1.03129508e+05, ...,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [7.75267258e+01, 1.11309643e+01, 1.02929469e+05, ...,\n        1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [1.25082756e+02, 7.78504133e+00, 1.01325000e+05, ...,\n        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [1.25070152e+02, 7.76335239e+00, 1.01324992e+05, ...,\n        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n       [1.25066811e+02, 7.70044041e+00, 1.01325008e+05, ...,\n        0.00000000e+00, 0.00000000e+00, 1.00000000e+00]], dtype=float32)>, edges=<tf.Tensor: shape=(61796, 3), dtype=float32, numpy=\narray([[ 0.00579996, -0.01206488,  0.01338659],\n       [-0.00720367, -0.01440071,  0.01610196],\n       [-0.00630522,  0.0145334 ,  0.0158422 ],\n       ...,\n       [ 0.30951977,  1.4802246 ,  1.5122392 ],\n       [ 1.0828505 ,  1.8325498 ,  2.1285684 ],\n       [-0.43042946,  1.2830333 ,  1.3533084 ]], dtype=float32)>, receivers=<tf.Tensor: shape=(61796,), dtype=int32, numpy=array([   69,    55,   159, ..., 10294, 10339, 10342])>, senders=<tf.Tensor: shape=(61796,), dtype=int32, numpy=array([  417,   302,   405, ..., 10262, 10330, 10308])>, globals=None, n_node=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([10466])>, n_edge=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([61796])>)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "aa = itr.next()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model and loss function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from AdamModLr import Adam\n",
    "\n",
    "lr = 1e-4\n",
    "# opt = snt.optimizers.Adam(lr)\n",
    "opt = Adam(lr)\n",
    "steps = 15\n",
    "#model = EncodeProcessDecode(steps, LINEAR_FEATURES, [128] * 2, [128] * 2 + [4])\n",
    "md = models[mod]\n",
    "model = md[\"model\"](**md[\"args\"])\n",
    "initial_learning_rate = lr\n",
    "decay_rate = 0.1\n",
    "decay_steps = 5e6\n",
    "learning_increase = 1e-6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def decayed_learning_rate(step):\n",
    "    return initial_learning_rate * decay_rate ** (step / decay_steps) + learning_increase"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def update_step(data, targets=('velocity')):\n",
    "    print(\"Tracing!\")\n",
    "    grp = toGraphsTuple(data, targets)\n",
    "    with tf.GradientTape() as tape:\n",
    "        los = model.loss(grp, data, targets=targets)  #change to loss\n",
    "\n",
    "    gradients = tape.gradient(los, model.trainable_variables)\n",
    "\n",
    "    opt.apply(gradients, model.trainable_variables)\n",
    "    return los"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n"
     ]
    }
   ],
   "source": [
    "update_step(aa, targets);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss(grp, data):\n",
    "    return model.loss(grp, data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    logdir = 'logs/tst/'\n",
    "    writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "    # Bracket the function call with\n",
    "    # tf.summary.trace_on() and tf.summary.trace_export().\n",
    "    tf.summary.trace_on(graph=True, profiler=True)\n",
    "    # Call only one tf.function when tracing.\n",
    "    z = loss(dd, d)\n",
    "    with writer.as_default():\n",
    "        tf.summary.trace_export(\n",
    "            name=\"my_func_trace\",\n",
    "            step=0,\n",
    "            profiler_outdir=logdir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "chck_root = \"models/fullnet/\"\n",
    "chck_name = mod\n",
    "\n",
    "chck = tf.train.Checkpoint(module=model)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(chck_root)\n",
    "if latest is not None:\n",
    "    print(\"loading\", latest)\n",
    "    chck.restore(latest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "F4Xnsg7MpzaY",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866708,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acumulating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if latest is None and not isinstance(model, EncodeProcessDecode):\n",
    "    print(\"Acumulating\")\n",
    "    for i in range(1000):\n",
    "        data = itr.next()\n",
    "        grp = toGraphsTuple(data, targets)\n",
    "        model.loss(grp, data,targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgZu39MbJi_z",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866709,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "if latest is None and not isinstance(model, EncodeProcessDecode):\n",
    "    print(\"Acumulating\")\n",
    "    for i in range(1000):\n",
    "        data = itr.next()\n",
    "        grp = toGraphsTuple(data)\n",
    "        model.loss(grp, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCL_h2riGcON",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866710,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "dt2 = load_dataset(data_path, data_train)\n",
    "dt2 = add_targets(dt2, targets, add_history=params[0]['history'])\n",
    "qq = iter(dt2).next()\n",
    "qqq = {}\n",
    "for i, j in qq.items():\n",
    "    qqq[i] = j[0]\n",
    "grp_ = toGraphsTuple(qqq, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.reduce_min(qqq['density']), tf.reduce_max(qqq['density']),tf.reduce_min(qqq['velocity'][0]), tf.reduce_max(qqq['velocity'][0]),tf.reduce_min(qqq['pressure']), tf.reduce_max(qqq['pressure'])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rxl7B_NWHdWC",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866710,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6-zse4oZlLr",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866711,
     "user_tz": -120,
     "elapsed": 23,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "if \"m\" in locals():\n",
    "    m.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sdIk7J4Gn-Z"
   },
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7az1IQah3pZ",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866712,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "res = [grp_, ]\n",
    "loss_mask = tf.logical_or(tf.equal(qqq['node_type'][:, 0], NodeType.NORMAL),\n",
    "                          tf.equal(qqq['node_type'][:, 0], NodeType.OUTFLOW))\n",
    "feat = grp_.nodes.shape\n",
    "loss_mask = tf.reshape(tf.concat([loss_mask for _ in range(grp_.nodes.shape[1])], -1), [-1, grp_.nodes.shape[1]])\n",
    "for i in range(600):\n",
    "    grp2_ = model(grp_, False)\n",
    "    grp_ = grp_.replace(nodes=tf.where(loss_mask, grp2_.nodes, grp_.nodes))\n",
    "    res.append(grp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EewpBxU7HoZI",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866712,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def toGraphsTupleOld(d):\n",
    "    send, recive = triangles_to_edges(d['cells'])\n",
    "    rel_pos = (tf.gather(d['mesh_pos'], send) - tf.gather(d['mesh_pos'], recive))\n",
    "    nodes_unique = tf.unique_with_counts(tf.reshape(d[\"node_type\"], [-1]))\n",
    "    dd = {\n",
    "        #\"nodes\": tf.concat([d[\"velocity\"],d[\"pressure\"],d[\"density\"],tf.cast(d[\"node_type\"],tf.float32),d[\"mesh_pos\"]],1),\n",
    "        \"nodes\": tf.concat([d['velocity'], tf.one_hot(tf.reshape(d[\"node_type\"], [-1]), NodeTypeCnt, dtype=tf.float32)],\n",
    "                           1),  # on change update loss function ^\n",
    "        \"senders\": send,\n",
    "        \"receivers\": recive,\n",
    "        \"edges\": tf.concat([\n",
    "            rel_pos,\n",
    "            tf.norm(rel_pos, axis=-1, keepdims=True)], 1)\n",
    "    }\n",
    "    return utils_tf.data_dicts_to_graphs_tuple([dd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6HE1HO-paOC",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866713,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "# fix mistake in data preparation\n",
    "if chck_root == \"models/new\":\n",
    "    grp_ = toGraphsTupleOld(qqq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYsAa0I3E3E4",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866714,
     "user_tz": -120,
     "elapsed": 25,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "res = [grp_, ]\n",
    "loss_mask = tf.logical_or(tf.equal(qqq['node_type'][:, 0], NodeType.NORMAL),\n",
    "                          tf.equal(qqq['node_type'][:, 0], NodeType.OUTFLOW))\n",
    "loss_mask = tf.reshape(tf.concat([loss_mask for _ in range(5)], -1), [-1, 5])\n",
    "for i in range(600):\n",
    "    grp2_ = model(grp_, False)\n",
    "    grp_ = grp_.replace(nodes=tf.where(loss_mask, grp2_.nodes, grp_.nodes))\n",
    "    res.append(grp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAvHsrlrNR8Y",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866714,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "grp_.nodes.shape, grp2_.nodes.shape, loss_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_x92ZzOSIFR",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866715,
     "user_tz": -120,
     "elapsed": 25,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import tri as mtri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sojXwyPSCjPn",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866715,
     "user_tz": -120,
     "elapsed": 25,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD-mCoFaRV_r",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866716,
     "user_tz": -120,
     "elapsed": 25,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "skip = 5\n",
    "num_steps = len(res)\n",
    "num_frames = num_steps // skip\n",
    "# compute bounds\n",
    "bounds = []\n",
    "bb_min, bb_max = tf.reduce_min(qq['velocity'][:, 0]), tf.reduce_max(qq['velocity'][:, 0])\n",
    "\n",
    "\n",
    "def animate(num):\n",
    "    global t\n",
    "    step = (num * skip) % num_steps\n",
    "    traj = (num * skip) // num_steps\n",
    "    ax.cla()\n",
    "    ax.set_xlim(-1, 2)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_autoscale_on(False)\n",
    "    vmin, vmax = bb_min, bb_max\n",
    "    pos = qqq['mesh_pos']\n",
    "    faces = qqq['cells']\n",
    "    velocity = res[step].nodes[..., :2].numpy()\n",
    "    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n",
    "    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax)\n",
    "    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n",
    "    ax.set_title('Trajectory %d Step %d' % (traj, step))\n",
    "    return fig,\n",
    "\n",
    "\n",
    "animate(0)\n",
    "plt.colorbar(t)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAk5i42t-uik",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866717,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "skip = 5\n",
    "num_steps = len(res)\n",
    "num_frames = num_steps // skip\n",
    "# compute bounds\n",
    "bounds = []\n",
    "\n",
    "bb_min, bb_max = tf.reduce_min(qq['velocity'][:, 0]), tf.reduce_max(qq['velocity'][:, 0])\n",
    "\n",
    "\n",
    "def animate(num):\n",
    "    global t\n",
    "    step = (num * skip) % num_steps\n",
    "    traj = (num * skip) // num_steps\n",
    "    ax.cla()\n",
    "    ax.set_xlim(-1, 2)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_autoscale_on(False)\n",
    "    vmin, vmax = bb_min, bb_max\n",
    "    pos = qq['mesh_pos'][0]\n",
    "    faces = qq['cells'][0]\n",
    "    velocity = qq['velocity'][step]\n",
    "    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n",
    "    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax)\n",
    "    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n",
    "    ax.set_title('Trajectory %d Step %d' % (traj, step))\n",
    "    return fig,\n",
    "\n",
    "\n",
    "animate(0)\n",
    "plt.colorbar(t)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "skip = 5\n",
    "num_steps = len(res)\n",
    "num_frames = num_steps // skip\n",
    "# compute bounds\n",
    "bounds = []\n",
    "\n",
    "bb_min, bb_max = 0, tf.reduce_max(qq['velocity'][:, 0])\n",
    "\n",
    "\n",
    "def animate(num):\n",
    "    global t\n",
    "    step = (num * skip) % num_steps\n",
    "    traj = (num * skip) // num_steps\n",
    "    ax.cla()\n",
    "    ax.set_xlim(-1, 2)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_autoscale_on(False)\n",
    "    vmin, vmax = bb_min, bb_max\n",
    "    pos = qq['mesh_pos'][0]\n",
    "    faces = qq['cells'][0]\n",
    "    velocity = tf.math.abs(qq['velocity'][step] - res[step].nodes[..., :2])\n",
    "    triang = mtri.Triangulation(pos[:, 0], pos[:, 1], faces)\n",
    "    t = ax.tripcolor(triang, velocity[:, 0], vmin=vmin, vmax=vmax, cmap='Reds')\n",
    "    ax.triplot(triang, 'ko-', ms=0.5, lw=0.3)\n",
    "    ax.set_title('Trajectory %d Step %d' % (traj, step))\n",
    "    return fig,\n",
    "\n",
    "\n",
    "animate(0)\n",
    "plt.colorbar(t)\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=num_frames, interval=200)\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ],
   "metadata": {
    "id": "k_531TOhTPL1",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866717,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUC2kys8BVfb",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004866718,
     "user_tz": -120,
     "elapsed": 26,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "bb_min, bb_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-1F-HpWKSJK",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867025,
     "user_tz": -120,
     "elapsed": 333,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "model._node_norm._std_with_epsilon(), model._node_norm._mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDos9sgYNAWO",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867027,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "qq['target|velocity'].shape, qq['velocity'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te9-5ridMn9J",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867029,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "r = tf.reduce_sum((qq['velocity'] - qq['target|velocity']) ** 2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z54kK29oQqSF",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867029,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "tt = [{i: qq[i][x] for i in qq.keys()} for x in range(599)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2Doz88iMIcF",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867030,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "lss = []\n",
    "for i in tt:\n",
    "    lss.append(model.loss(toGraphsTuple(i), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-WgXhS0PoJ2",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867031,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "lss = [x.numpy() for x in lss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPMBBA--UGY5",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867032,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(lss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Iw9fT7tSHry",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867032,
     "user_tz": -120,
     "elapsed": 20,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "1e7 / (1000 * 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nO_jH39ETn35",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867033,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    "ee = [x.shape.as_list() for x in model.trainable_variables]\n",
    "sum([(y[0] if len(y) == 1 else y[0] * y[1]) for y in ee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1KK9yuhWwXG",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1651004867033,
     "user_tz": -120,
     "elapsed": 20,
     "user": {
      "displayName": "david horsky",
      "userId": "15225206442244274917"
     }
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "graph_lib.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}